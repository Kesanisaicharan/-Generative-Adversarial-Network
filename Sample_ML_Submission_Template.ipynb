{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kesanisaicharan/-Generative-Adversarial-Network/blob/main/Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Flipkart customer service satisfaction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxUjikOAhcj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -KESANI. SAI CHARAN\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Summary -\n",
        "\n",
        "This project focuses on analyzing Flipkart e-commerce data to gain valuable insights into customer behavior, product trends, and pricing patterns. With the rapid growth of online shopping platforms, understanding customer preferences and product performance has become essential for improving business strategies and enhancing user experience. The main objective of this project is to explore Flipkart product data and apply data analytics and machine learning techniques to extract meaningful information and build predictive models that support better decision-making.\n",
        "\n",
        "The project begins with data collection and preprocessing, where raw product data is cleaned by handling missing values, removing duplicate entries, and transforming categorical attributes into numerical formats suitable for analysis. This ensures data consistency and improves model accuracy. After preprocessing, exploratory data analysis (EDA) is performed to understand product distributions across categories, pricing variations, discount trends, and customer rating patterns. Visualizations such as bar charts, histograms, and scatter plots are used to identify relationships between variables like price, discount, and ratings, helping uncover hidden trends in customer purchasing behavior.\n",
        "\n",
        "Following data analysis, feature engineering techniques are applied to select important attributes that influence product pricing and customer engagement. A machine learning model is then developed to predict product prices or customer ratings based on selected features such as category, brand, discount percentage, and user ratings. Algorithms such as Linear Regression or Logistic Regression are used due to their simplicity, interpretability, and effectiveness for structured data. The dataset is divided into training and testing sets to evaluate the model’s performance objectively.\n",
        "\n",
        "The trained model is evaluated using standard performance metrics such as accuracy, mean absolute error, root mean square error, and R² score, depending on whether the task is classification or regression. These metrics help measure how well the model generalizes to unseen data. The project demonstrates that machine learning can effectively capture pricing trends and customer behavior patterns within Flipkart’s product ecosystem.\n",
        "\n",
        "The final stage of the project involves result interpretation and deployment readiness. The findings from data analysis and model predictions can assist businesses in optimizing product pricing strategies, improving inventory management, and enhancing customer satisfaction. Additionally, the project provides a foundation for building recommendation systems, sentiment analysis tools, or real-time dashboards for e-commerce platforms.\n",
        "\n",
        "In conclusion, this Flipkart data analysis project successfully demonstrates how data science techniques can be applied to real-world e-commerce datasets to derive actionable insights and build predictive systems. It highlights the importance of data-driven decision-making in today’s competitive digital marketplace. Future enhancements may include integrating real-time product data scraping, applying deep learning models for better prediction accuracy, and deploying the solution as a web-based application for business users.Overall, this project offers a practical and scalable approach to understanding and improving e-commerce operations through analytics and machine learning."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "Write Problem Statement Here.\n",
        "\n",
        "In today’s competitive e-commerce environment, platforms like Flipkart handle large volumes of customer interactions and service requests. Managing customer issues efficiently while maintaining high satisfaction levels is a major challenge. Raw customer support data alone does not provide clear insights into customer behavior, service performance, or potential dissatisfaction risks. Therefore, there is a need for a data-driven system that can analyze customer support records and predict customer satisfaction outcomes. This project aims to apply machine learning techniques to customer support data to identify key factors influencing satisfaction and improve service quality and operational efficiency.\n",
        "\n",
        "GOAL - The main goal of this project is to analyze customer support data and build a machine learning model that predicts customer satisfaction based on ticket attributes such as issue type, support channel, response time, and resolution status. This helps organizations improve customer service performance, reduce response times, enhance customer experience, and make informed business decisions using data-driven insights\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"Customer_support_data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "data.isnull().sum().plot(kind='bar', figsize=(8,4))\n",
        "plt.title(\"Missing Values Count per Column\")\n",
        "plt.ylabel(\"Number of Missing Values\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "df = data.copy()\n",
        "\n",
        "# Handling missing values\n",
        "\n",
        "# Drop columns with extremely high missing values (over ~80%)\n",
        "# connected_handling_time: 85665 missing out of 85907 (99.7% missing)\n",
        "# order_date_time: 68693 missing out of 85907 (79.9% missing)\n",
        "df.drop(columns=['connected_handling_time', 'order_date_time'], inplace=True)\n",
        "\n",
        "# Impute numerical column Item_price with median\n",
        "df['Item_price'].fillna(df['Item_price'].median(), inplace=True)\n",
        "\n",
        "# Impute categorical/object columns\n",
        "# Customer Remarks: 57165 missing. Fill with 'No Remarks'\n",
        "df['Customer Remarks'].fillna('No Remarks', inplace=True)\n",
        "# Order_id: 18232 missing. Fill with 'Unknown'\n",
        "df['Order_id'].fillna('Unknown', inplace=True)\n",
        "# Customer_City: 68828 missing. Fill with 'Unknown'\n",
        "df['Customer_City'].fillna('Unknown', inplace=True)\n",
        "# Product_category: 68711 missing. Fill with 'Unknown'\n",
        "df['Product_category'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Convert date columns to datetime objects for easier manipulation\n",
        "df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], format='%d/%m/%Y %H:%M')\n",
        "df['issue_responded'] = pd.to_datetime(df['issue_responded'], format='%d/%m/%Y %H:%M')\n",
        "# Survey_response_Date format is different, handle with errors='coerce'\n",
        "df['Survey_response_Date'] = pd.to_datetime(df['Survey_response_Date'], errors='coerce')\n",
        "\n",
        "# Display the info after wrangling to show changes\n",
        "print(\"DataFrame Info after Data Wrangling:\")\n",
        "df.info()\n",
        "print(\"\\nMissing values count after wrangling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visuals\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "\n",
        "# Count tickets by category\n",
        "category_counts = df['category'].value_counts()\n",
        "\n",
        "# Plot\n",
        "sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Ticket Count by Category', fontsize=16)\n",
        "plt.xlabel('Category', fontsize=12)\n",
        "plt.ylabel('Number of Tickets', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visuals\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "# Count tickets by sub-category and select top 10\n",
        "subcat_counts = df['Sub-category'].value_counts().head(10)\n",
        "\n",
        "# Plot horizontal bar chart\n",
        "sns.barplot(x=subcat_counts.values, y=subcat_counts.index, palette='magma')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Top 10 Sub-Categories by Ticket Count', fontsize=16)\n",
        "plt.xlabel('Number of Tickets', fontsize=12)\n",
        "plt.ylabel('Sub-Category', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visuals\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "# Count tickets by city and select top 10\n",
        "city_counts = df['Customer_City'].value_counts().head(10)\n",
        "\n",
        "# Plot horizontal bar chart\n",
        "sns.barplot(x=city_counts.values, y=city_counts.index, palette='coolwarm')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Top 10 Cities by Ticket Volume', fontsize=16)\n",
        "plt.xlabel('Number of Tickets', fontsize=12)\n",
        "plt.ylabel('Customer City', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate response time in days\n",
        "df['response_time'] = df['issue_responded'] - df['Issue_reported at']\n",
        "df['response_time_days'] = df['response_time'].dt.total_seconds() / (3600 * 24)\n",
        "\n",
        "# Set style for better visuals\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "# Boxplot of response time\n",
        "sns.boxplot(x=df['response_time_days'], color='skyblue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Distribution of Response Time (Days)', fontsize=16)\n",
        "plt.xlabel('Response Time (Days)', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "\n",
        "# Count CSAT scores\n",
        "csat_counts = df['CSAT Score'].value_counts().sort_index()\n",
        "\n",
        "# Plot\n",
        "sns.barplot(x=csat_counts.index, y=csat_counts.values, palette='Set2')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Distribution of CSAT Scores', fontsize=16)\n",
        "plt.xlabel('CSAT Score', fontsize=12)\n",
        "plt.ylabel('Number of Responses', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "\n",
        "# Count tickets by shift\n",
        "shift_counts = df['Agent Shift'].value_counts()\n",
        "\n",
        "# Plot\n",
        "sns.barplot(x=shift_counts.index, y=shift_counts.values, palette='pastel')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Ticket Volume by Agent Shift', fontsize=16)\n",
        "plt.xlabel('Agent Shift', fontsize=12)\n",
        "plt.ylabel('Number of Tickets', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "\n",
        "# Boxplot: CSAT vs Response Time\n",
        "sns.boxplot(x='CSAT Score', y='response_time_days', data=df, palette='Set3')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('CSAT Score vs Response Time', fontsize=16)\n",
        "plt.xlabel('CSAT Score', fontsize=12)\n",
        "plt.ylabel('Response Time (Days)', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "# Calculate average CSAT per agent and select top 10\n",
        "agent_csat = df.groupby('Agent_name')['CSAT Score'].mean().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plot\n",
        "sns.barplot(x=agent_csat.values, y=agent_csat.index, palette='viridis')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Top 10 Agents by Average CSAT Score', fontsize=16)\n",
        "plt.xlabel('Average CSAT Score', fontsize=12)\n",
        "plt.ylabel('Agent Name', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "# Calculate average CSAT per category\n",
        "category_csat = df.groupby('category')['CSAT Score'].mean().sort_values(ascending=False)\n",
        "\n",
        "# Plot\n",
        "sns.barplot(x=category_csat.index, y=category_csat.values, palette='coolwarm')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Average CSAT Score by Category', fontsize=16)\n",
        "plt.xlabel('Category', fontsize=12)\n",
        "plt.ylabel('Average CSAT Score', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 10 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get top 6 product categories\n",
        "product_counts = df['Product_category'].value_counts().head(6)\n",
        "\n",
        "# Plot pie chart\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(product_counts.values, labels=product_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Ticket Distribution by Product Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Top 10 product categories\n",
        "product_counts = df['Product_category'].value_counts().head(10).sort_values()\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Lollipop chart\n",
        "plt.hlines(y=product_counts.index, xmin=0, xmax=product_counts.values, color='skyblue', alpha=0.7, linewidth=3)\n",
        "plt.plot(product_counts.values, product_counts.index, \"o\", markersize=10, color='orange')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Top 10 Product Categories by Ticket Volume', fontsize=16)\n",
        "plt.xlabel('Number of Tickets', fontsize=12)\n",
        "plt.ylabel('Product Category', fontsize=12)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate average response time and ticket count per category\n",
        "category_stats = df.groupby('category').agg({'response_time_days':'mean', 'category':'count'})\n",
        "category_stats.rename(columns={'category':'ticket_count'}, inplace=True)\n",
        "category_stats = category_stats.sort_values('response_time_days')\n",
        "\n",
        "# Scatter/Bubble plot\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.scatter(category_stats['response_time_days'], category_stats.index,\n",
        "            s=category_stats['ticket_count']*0.5,  # scale bubble size\n",
        "            color='skyblue', alpha=0.7, edgecolor='black')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Average Response Time by Category (Bubble Size = Ticket Count)', fontsize=16)\n",
        "plt.xlabel('Average Response Time (Days)', fontsize=12)\n",
        "plt.ylabel('Category', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSAT Score by product category\n",
        "plt.figure(figsize=(12,8)) # fixes the size of the visualization\n",
        "# plot the boxplot\n",
        "sns.boxplot(x='Product_category', y = 'CSAT Score', data=df, palette='Set1')\n",
        "# title and labels\n",
        "plt.title('CSAT Score by Product Category')\n",
        "plt.xlabel('Product category')\n",
        "plt.ylabel('CSAT Score')\n",
        "plt.xticks(rotation=90) # For better readability\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select numeric columns for correlation\n",
        "numeric_cols = ['Item_price', 'response_time_days', 'CSAT Score']\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0, linewidths=0.5)\n",
        "plt.title('Correlation Heatmap of Numeric Variables', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select numeric columns for pair plot\n",
        "numeric_cols = ['Item_price', 'response_time_days', 'CSAT Score']\n",
        "\n",
        "# Plot pair plot\n",
        "sns.pairplot(df[numeric_cols], kind='scatter', diag_kind='kde', plot_kws={'alpha':0.6, 's':50, 'edgecolor':'k'}, diag_kws={'shade':True})\n",
        "plt.suptitle('Pair Plot of Numeric Variables', fontsize=16, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-value\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Calculate ticket count and average CSAT per supervisor\n",
        "supervisor_stats = df.groupby('Supervisor').agg(\n",
        "    ticket_count=('Supervisor', 'count'),\n",
        "    avg_csat=('CSAT Score', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# Perform Pearson correlation\n",
        "corr_coeff, p_value = pearsonr(supervisor_stats['ticket_count'], supervisor_stats['avg_csat'])\n",
        "\n",
        "print(\"Correlation coefficient:\", corr_coeff)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Ensure response_time_days column exists\n",
        "# If not, calculate it\n",
        "df['response_time_days'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / (3600*24)\n",
        "\n",
        "# Drop rows with missing values in CSAT or response time\n",
        "df_test = df.dropna(subset=['CSAT Score', 'response_time_days'])\n",
        "\n",
        "# Perform Pearson correlation\n",
        "corr_coeff, p_value = pearsonr(df_test['response_time_days'], df_test['CSAT Score'])\n",
        "\n",
        "print(\"Correlation coefficient:\", corr_coeff)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Calculate response time in days if not already done\n",
        "df['response_time_days'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / (3600*24)\n",
        "\n",
        "# Drop missing values\n",
        "df_test = df.dropna(subset=['response_time_days', 'Product_category'])\n",
        "\n",
        "# Separate Electronics and Other categories\n",
        "electronics = df_test[df_test['Product_category'] == 'Electronics']['response_time_days']\n",
        "others = df_test[df_test['Product_category'] != 'Electronics']['response_time_days']\n",
        "\n",
        "# Perform independent t-test\n",
        "t_stat, p_value = ttest_ind(electronics, others, equal_var=False)  # Welch's t-test\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df = data.copy()\n",
        "\n",
        "# Drop columns with very high missing values\n",
        "df.drop(columns=['connected_handling_time', 'order_date_time'], inplace=True)\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "df['Item_price'].fillna(df['Item_price'].median(), inplace=True)\n",
        "\n",
        "# Fill missing categorical values\n",
        "df['Customer Remarks'].fillna('No Remarks', inplace=True)\n",
        "df['Order_id'].fillna('Unknown', inplace=True)\n",
        "df['Customer_City'].fillna('Unknown', inplace=True)\n",
        "df['Product_category'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Check remaining missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Define the cap_outliers function\n",
        "def cap_outliers(series, lower_bound_factor=1.5, upper_bound_factor=1.5):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - (lower_bound_factor * IQR)\n",
        "    upper_bound = Q3 + (upper_bound_factor * IQR)\n",
        "    return series.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "# Before outlier treatment\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(x=df['Item_price'])\n",
        "plt.title('Before Outlier Treatment - Item Price')\n",
        "\n",
        "# After outlier treatment\n",
        "df['Item_price_capped'] = cap_outliers(df['Item_price'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(x=df['Item_price_capped'])\n",
        "plt.title('After Outlier Treatment - Item Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "label_cols = ['Agent_name', 'Supervisor', 'Manager', 'Customer_City', 'Product_category']\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "df = pd.get_dummies(df, columns=['category', 'Agent Shift'], drop_first=True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "import re\n",
        "\n",
        "contractions_dict = {\n",
        "    \"can't\": \"cannot\", \"won't\": \"will not\", \"don't\": \"do not\",\n",
        "    \"didn't\": \"did not\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
        "    \"wasn't\": \"was not\", \"weren't\": \"were not\", \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\", \"hadn't\": \"had not\", \"wouldn't\": \"would not\",\n",
        "    \"shouldn't\": \"should not\", \"couldn't\": \"could not\", \"mustn't\": \"must not\",\n",
        "    \"it's\": \"it is\", \"that's\": \"that is\", \"what's\": \"what is\",\n",
        "    \"there's\": \"there is\", \"I'm\": \"I am\", \"you're\": \"you are\",\n",
        "    \"they're\": \"they are\", \"we're\": \"we are\", \"I've\": \"I have\",\n",
        "    \"you've\": \"you have\", \"we've\": \"we have\", \"they've\": \"they have\",\n",
        "    \"I'll\": \"I will\", \"you'll\": \"you will\", \"he'll\": \"he will\",\n",
        "    \"she'll\": \"she will\", \"they'll\": \"they will\", \"we'll\": \"we will\"\n",
        "}\n",
        "\n",
        "def expand_contractions(text):\n",
        "    for contraction, full_form in contractions_dict.items():\n",
        "        text = re.sub(r\"\\b{}\\b\".format(contraction), full_form, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "# Apply to textual column (example: Customer Remarks)\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).apply(expand_contractions)\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# Convert text to lowercase\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).str.lower()\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "# Remove punctuation from text\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).str.translate(str.maketrans('', '', string.punctuation))\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)     # Remove URLs\n",
        "    text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)       # Remove words containing digits\n",
        "    return text\n",
        "\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).apply(\n",
        "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
        ")\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "# Remove extra spaces\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).str.strip().str.replace(r'\\s+', ' ', regex=True)\n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "rephrase_dict = {\n",
        "    \"pls\": \"please\",\n",
        "    \"asap\": \"as soon as possible\",\n",
        "    \"u\": \"you\",\n",
        "    \"ur\": \"your\",\n",
        "    \"thx\": \"thanks\",\n",
        "    \"btw\": \"by the way\",\n",
        "    \"msg\": \"message\"\n",
        "}\n",
        "\n",
        "def rephrase_text(text):\n",
        "    words = text.split()\n",
        "    return \" \".join([rephrase_dict.get(word, word) for word in words])\n",
        "\n",
        "df['Customer Remarks'] = df['Customer Remarks'].astype(str).apply(rephrase_text)\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Simple whitespace-based tokenization\n",
        "df['Customer Remarks_tokens'] = df['Customer Remarks'].astype(str).apply(lambda x: x.split())\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhOU2Ek4Y3mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example: lemmatize tokenized text\n",
        "df['Customer Remarks_lemmatized'] = df['Customer Remarks_tokens'].apply(\n",
        "    lambda tokens: [lemmatizer.lemmatize(word) for word in tokens]\n",
        ")\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "import nltk\n",
        "\n",
        "# Download the necessary tokenizer\n",
        "nltk.download('punkt')  # This is the standard tokenizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError: Resource punkt_tab not found\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Added to resolve LookupError: Resource averaged_perceptron_tagger_eng not found\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Fill missing remarks and convert to string\n",
        "df['Customer Remarks'] = df['Customer Remarks'].fillna('').astype(str)\n",
        "\n",
        "# Expand contractions (simple example, you can add more)\n",
        "contractions_dict = {\"can't\": \"cannot\", \"don't\": \"do not\", \"i'm\": \"i am\"}\n",
        "\n",
        "def expand_contractions(text):\n",
        "    for contraction, full_form in contractions_dict.items():\n",
        "        text = re.sub(r'\\b{}\\b'.format(contraction), full_form, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "df['Customer Remarks'] = df['Customer Remarks'].apply(expand_contractions)\n",
        "\n",
        "# Lowercase\n",
        "df['Customer Remarks'] = df['Customer Remarks'].str.lower()\n",
        "\n",
        "# Remove URLs and words with digits\n",
        "df['Customer Remarks'] = df['Customer Remarks'].apply(lambda x: re.sub(r'http\\S+|www\\S+', '', x))\n",
        "df['Customer Remarks'] = df['Customer Remarks'].apply(lambda x: re.sub(r'\\b\\w*\\d\\w*\\b', '', x))\n",
        "\n",
        "# Remove punctuation\n",
        "df['Customer Remarks'] = df['Customer Remarks'].str.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['Customer Remarks'] = df['Customer Remarks'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Remove extra spaces\n",
        "df['Customer Remarks'] = df['Customer Remarks'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "# Tokenization using nltk.word_tokenize (now it will work)\n",
        "df['Customer Remarks_tokens'] = df['Customer Remarks'].apply(nltk.word_tokenize)\n",
        "\n",
        "# POS tagging\n",
        "df['Customer Remarks_POS'] = df['Customer Remarks_tokens'].apply(nltk.pos_tag)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['Customer Remarks_lemmatized'] = df['Customer Remarks_tokens'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
        "\n",
        "# Check result\n",
        "print(df[['Customer Remarks', 'Customer Remarks_tokens', 'Customer Remarks_POS', 'Customer Remarks_lemmatized']].head())"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Ensure no missing values\n",
        "df['Customer Remarks'] = df['Customer Remarks'].fillna('').astype(str)\n",
        "\n",
        "#  Bag of Words\n",
        "bow_vectorizer = CountVectorizer()\n",
        "X_bow = bow_vectorizer.fit_transform(df['Customer Remarks'])\n",
        "\n",
        "#  TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['Customer Remarks'])\n",
        "\n",
        "# N-grams (TF-IDF)\n",
        "ngram_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "X_ngram = ngram_vectorizer.fit_transform(df['Customer Remarks'])\n",
        "\n",
        "# Output shapes\n",
        "print(\"Bag of Words Shape:\", X_bow.shape)\n",
        "print(\"TF-IDF Shape:\", X_tfidf.shape)\n",
        "print(\"N-gram TF-IDF Shape:\", X_ngram.shape)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#  CREATE NEW FEATURES\n",
        "\n",
        "# Ensure datetime format\n",
        "df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], errors='coerce')\n",
        "df['issue_responded'] = pd.to_datetime(df['issue_responded'], errors='coerce')\n",
        "\n",
        "# Response time features\n",
        "df['response_time_hours'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / 3600\n",
        "df['response_time_days'] = df['response_time_hours'] / 24\n",
        "\n",
        "# Price category\n",
        "df['price_category'] = pd.cut(df['Item_price'],\n",
        "                               bins=[0,500,2000,5000,10000],\n",
        "                               labels=['Low','Medium','High','Premium'])\n",
        "\n",
        "# Agent workload feature\n",
        "df['agent_ticket_load'] = df.groupby('Agent_name')['Order_id'].transform('count')\n",
        "\n",
        "# CSAT band feature\n",
        "df['csat_band'] = pd.cut(df['CSAT Score'],\n",
        "                          bins=[0,2,4,5],\n",
        "                          labels=['Low','Medium','High'])\n",
        "\n",
        "# REMOVE HIGHLY CORRELATED FEATURES\n",
        "\n",
        "num_cols = df.select_dtypes(include=np.number)\n",
        "corr_matrix = num_cols.corr().abs()\n",
        "\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [col for col in upper.columns if any(upper[col] > 0.85)]\n",
        "\n",
        "df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "print(\"Dropped highly correlated columns:\", to_drop)\n",
        "#  FINAL DATAFRAME CHECK\n",
        "print(df.head())\n",
        "print(\"Final shape:\", df.shape)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Separate features and target\n",
        "X = df.select_dtypes(include=np.number).drop(columns=['CSAT Score'])\n",
        "y = df['CSAT Score']\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get feature importance\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Select top 10 features\n",
        "indices = np.argsort(importances)[-10:]\n",
        "selected_features = X.columns[indices]\n",
        "\n",
        "print(\"Top Selected Features:\", selected_features.tolist())"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "import numpy as np\n",
        "\n",
        "# Log transformation to reduce skewness\n",
        "df['Item_price_log'] = np.log1p(df['Item_price'])\n",
        "df['response_time_hours_log'] = np.log1p(df['response_time_hours'])\n",
        "\n",
        "# Check transformed data\n",
        "print(df[['Item_price', 'Item_price_log', 'response_time_hours', 'response_time_hours_log']].head())    #Yes, the data needed transformation. I used log transformation on skewed numerical features like Item_price and response_time_hours to reduce skewness, handle outliers, and improve model performance by making the data more normally distributed.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Apply scaling\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# Check result\n",
        "print(df[num_cols].head())"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Example: using TF-IDF matrix from Customer Remarks\n",
        "# Assuming X_tfidf is your TF-IDF vectorized text\n",
        "# X_tfidf = tfidf_vectorizer.fit_transform(df['Customer Remarks'])\n",
        "\n",
        "# Reduce dimensions to 10 components\n",
        "svd = TruncatedSVD(n_components=10, random_state=42)\n",
        "X_svd = svd.fit_transform(X_tfidf)\n",
        "\n",
        "# Create a DataFrame with reduced components\n",
        "df_svd = pd.DataFrame(X_svd, columns=[f'SVD{i+1}' for i in range(X_svd.shape[1])])\n",
        "\n",
        "# Check result\n",
        "print(df_svd.head())\n",
        "print(\"Explained Variance Ratio:\", svd.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features (X) and target (y)\n",
        "# Assume 'CSAT Score' is the target\n",
        "X = df.drop(columns=['CSAT Score'])\n",
        "y = df['CSAT Score']\n",
        "\n",
        "# Split data: 80% train, 20% test (common for real-world datasets)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Check shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('CSAT Score', axis=1)\n",
        "y = df['CSAT Score']\n",
        "\n",
        "# Convert datetime columns to numeric\n",
        "for col in X.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']):\n",
        "    X[col] = X[col].view('int64')  # convert to timestamp\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in X.select_dtypes(include=['object', 'category']):\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Fill missing values\n",
        "X = X.fillna(X.median(numeric_only=True))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Encode y_train and y_test to integer labels for classification\n",
        "# This is necessary because CSAT Score was scaled to floats, but classifiers need discrete integers\n",
        "le_csat = LabelEncoder()\n",
        "y_train_encoded = le_csat.fit_transform(y_train)\n",
        "y_test_encoded = le_csat.transform(y_test)\n",
        "\n",
        "# Handle imbalance using class weights\n",
        "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "model.fit(X_train, y_train_encoded)\n",
        "\n",
        "print(\" Model trained successfully without errors\")"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 (Random Forest) Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Random Forest classifier : \")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test_encoded, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred_rf, zero_division=0))\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get classification report as dictionary\n",
        "report = classification_report(y_test_encoded, y_pred_rf, output_dict=True, zero_division=0)\n",
        "\n",
        "# Convert to DataFrame\n",
        "report_df = pd.DataFrame(report).iloc[:-1, :].T\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(report_df[['precision', 'recall', 'f1-score']], annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title(\"Model Evaluation Metrics Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_rf.best_estimator_\n",
        "\n",
        "# Predict\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Best Parameters:\", grid_rf.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test_encoded, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred_rf, zero_division=0))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ML Model - 2 (Logistic Regression)\n",
        "\n",
        "# Fit the Algorithm\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Logistic Regression (Default Parameters): \")\n",
        "print(\"Accuracy Score: \", accuracy_score(y_test_encoded, y_pred_lr))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred_lr, zero_division=0))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_mat = confusion_matrix(y_test_encoded, y_pred_lr)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Logistic Regression - Confusion Matrix (Default)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Hyperparameter Tuning using GridSearch CV\n",
        "# ------------------------------------------\n",
        "\n",
        "param_grid = {\n",
        "    'C' : [0.01, 0.1, 1, 10],\n",
        "    'penalty' : ['l2'],\n",
        "    'solver' : ['lbfgs', 'saga'],\n",
        "    'max_iter' : [500, 1000]\n",
        "}\n",
        "\n",
        "grid_search_lr = GridSearchCV(\n",
        "    LogisticRegression(multi_class='multinomial', random_state = 42),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------------------\n",
        "# Fit the algorithm\n",
        "# ------------------------------------------\n",
        "\n",
        "grid_search_lr.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best parameters found: \", grid_search_lr.best_params_)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Predict the model\n",
        "# ------------------------------------------\n",
        "\n",
        "best_lr = grid_search_lr.best_estimator_\n",
        "y_pred = best_lr.predict(X_test)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Evaluation\n",
        "# ------------------------------------------\n",
        "\n",
        "print(\"\\nLogistic Regression with GridSearchCV: \")\n",
        "print(\"Accuracy Score: \", accuracy_score(y_test_encoded, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred, zero_division = 0))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_mat = confusion_matrix(y_test_encoded, y_pred)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Logistic Regression - Confusion Matrix (GridSearchCV)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# The target variable y_train and y_test currently hold scaled CSAT scores\n",
        "# with unique values like [-2, -1, 0].\n",
        "# XGBoost Classifier expects class labels to be consecutive integers starting from 0 (e.g., 0, 1, 2).\n",
        "# We need to encode these existing scaled scores into 0-indexed labels.\n",
        "\n",
        "# Use LabelEncoder to transform the scaled y values into 0-indexed classes\n",
        "le_xgb = LabelEncoder()\n",
        "y_train_xgb = le_xgb.fit_transform(y_train)\n",
        "y_test_xgb = le_xgb.transform(y_test)\n",
        "\n",
        "# Determine the number of classes for XGBoost\n",
        "num_classes_xgb = len(le_xgb.classes_)\n",
        "\n",
        "# Initialize XGBClassifier\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=num_classes_xgb,\n",
        "                    random_state=42, eval_metric='mlogloss')\n",
        "xgb.fit(X_train, y_train_xgb)\n",
        "\n",
        "# Predict on the model (raw 0-indexed predictions)\n",
        "y_pred_xgb_raw = xgb.predict(X_test)\n",
        "\n",
        "# To evaluate against the original scaled y_test values, we need to inverse transform the predictions\n",
        "# and compare them with the inverse transformed y_test for meaningful classification metrics.\n",
        "# Or, keep y_test as 0-indexed for comparison.\n",
        "# Let's compare y_pred_xgb_raw with y_test_xgb (both 0-indexed)\n",
        "\n",
        "# Evaluate using the 0-indexed labels\n",
        "print(\"XGBoost classifier (Default parameters): \")\n",
        "print(\"Accuracy Score: \", accuracy_score(y_test_xgb, y_pred_xgb_raw))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_xgb, y_pred_xgb_raw, zero_division=0))"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get classification report as dictionary for the XGBoost predictions\n",
        "report_xgb = classification_report(y_test_xgb, y_pred_xgb_raw, output_dict=True, zero_division=0)\n",
        "\n",
        "# Convert to DataFrame\n",
        "report_xgb_df = pd.DataFrame(report_xgb).iloc[:-1, :].T\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(report_xgb_df[['precision', 'recall', 'f1-score']], annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title(\"XGBoost Model Evaluation Metrics Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Hyperparameter Tuning using GridSearch CV\n",
        "# ------------------------------------------\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators' : [100, 150],\n",
        "    'max_depth' : [3, 6, 10],\n",
        "    'learning_rate' : [0.01, 0.1],\n",
        "    'subsample' : [0.8, 1],\n",
        "    'colsample_bytree' : [0.8, 1]\n",
        "}\n",
        "\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    estimator=XGBClassifier(eval_metric='mlogloss', objective='multi:softmax', random_state = 42),\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------------------\n",
        "# Fit the algorithm\n",
        "# ------------------------------------------\n",
        "\n",
        "grid_search_xgb.fit(X_train, y_train_xgb)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best parameters found: \", grid_search_xgb.best_params_)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Predict the model\n",
        "# ------------------------------------------\n",
        "\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "# Make predictions as 0-indexed labels for evaluation against y_test_xgb\n",
        "y_pred_xgb_eval = best_xgb.predict(X_test)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Evaluation\n",
        "# ------------------------------------------\n",
        "\n",
        "print(\"\\nXGBClassifier (with GridSearchCV): \")\n",
        "print(\"Accuracy Score: \", accuracy_score(y_test_xgb, y_pred_xgb_eval))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_xgb, y_pred_xgb_eval, zero_division = 0))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_xgb, y_pred_xgb_eval)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title(\"XGBoost - Confusion Matrix (GridSearchCV): \")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the file\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Save the model to a .pkl file\n",
        "with open ('best_xgb.pkl', 'wb') as file:\n",
        "  pickle.dump(best_xgb, file)\n",
        "\n",
        "print(\"Model saved as: 'best_xgb.pkl'\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the file and predict the unseen data.\n",
        "import pickle\n",
        "\n",
        "# Save the model to a .pkl file\n",
        "with open ('best_xgb.pkl', 'rb') as file:\n",
        "  loaded_model = pickle.load(file)\n",
        "\n",
        "# Select a few samples from test data\n",
        "unseen_samples = X_test.sample(5, random_state = 1)\n",
        "\n",
        "# Predict using the loaded model\n",
        "predictions = loaded_model.predict(unseen_samples) + 1  # Add 1 to match CSAT score scale (1-5)\n",
        "\n",
        "# Display predictions\n",
        "print(\"Predicted CSAT score for unseen data: \")\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}